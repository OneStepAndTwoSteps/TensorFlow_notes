
__监督学习：__

监督学习是机器学习的一种方法，指从训练数据(输入和预期输出)中学习到一个模型(函数)，并根据模型可以推断新实例的方法。

函数的输出通常为一个连续值(回归分析)或者类别标签(分类)

![Image_text](https://raw.githubusercontent.com/OneStepAndTwoSteps/TensorFlow_notes/master/static/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B.png)

__举个例子：__
			
我们在训练的过程当中一定是需要训练数据的，比如一些经典的猫狗分类、人脸识别等，为了能让机器识别出什么是狗，什么是猫，前提是我们需要很多的训练数据(图片)，图片也已经是打好了标签，然后告诉你什么是猫，什么是狗，这些其实就是我们的训练数据，基于训练数据来学习一个函数，拟合一个模型的方法，我们称之为监督学习的方法，除了监督学习之外，我们还会有一些半监督学习，无监督学习。比如大家熟悉的alphago 从它升级到alpha-zero的过程中其实就是成为了无监督学习的算法了。这个时候只要我的科学家告诉他围棋的规则是什么，围棋该如何下，围棋的胜利条件是什么，他就可以学习出如何下围棋才能获胜。刚开始的alphago其实是需要从大量的人类棋谱中进行学习，这其实是一种监督学习的算法。

__监督学习和无监督学习都有各自的领域，没有优劣之分。__ 在一些特定的场景中监督学习可以表现的非常好，一个大家身边很常见的例子：

比如在大家在taobao或者在Amazon进行购物的时候他就有推荐系统，他会给你推荐什么是你可能喜欢的，其实这就是监督学习的机器学习算法，
			
监督学习的输出通常为一个连续值(回归分析)或者类别标签(分类)


当他为连续值的时候，我们通常会使用回归分析的算法拟合出我们理想中的输出值，还有一种就是分类算法，当你输入一个数据，会通过分类告诉你它可能是一个什么类别的东西，我们会输出一个标签。比如说你输出了很多图片，机器会帮你判断出哪些是苹果哪些是香蕉，这就是分类，也是监督学习中的一种。

监督学习流程 就是上图

	针对房价预测的问题，我们知道房子的具体位置，房子的大小，房子是100平的还是200平的，房子是三室一厅还是两室一厅，这些其实就是我们的输入数据。
	历史的售房数据，比如说我们三室一厅的120平的房子历史售房价格可能在500W左右，两室一厅的90平的房子售价可能在300W左右，这些都是我们的训练数据
	我们的训练数据通过特定的算法之后，可以得到一个输出值(预测值)。

	训练数据 + 学习算法拟合出的函数我们称为模型，以房价预测为例模型的输入数据就是房子的大小，卧室的数量，输出就是房屋的价格。

当我们把模型拟合出来之后，我们是想要它有作用的，比如我们根据历史的房子的信息和售房记录拟合出了一个房屋售价模型，当有新的数据输入的时候比如我们输入的房子是四室一厅，房子的大小是500平，那他会帮我们预测出，房子的售价大概是多少钱，这就是我们模型发挥作用的时候。他会通过输入数据来判断出一个推断的结果，这个推断的结果虽然会和市场上的价格会有误差，但是对我们来说它还是存在指导意义。


__这其实就是我们监督学习的一个流程框架__

	我们通过训练数据和学习算法得到一个模型，模型在我们原有的数据上如果拟合的足够好，那我们输入要预测的数据和预测出来的值那将对我们有指导意义


__监督学习典型算法：__

	线性回归（Linear Regression） 
	逻辑回归（Logistic Regression）
	决策树（Decision Tree）
	随机森林（Random Forest）
	最近邻算法（k-NN）
	朴素叶贝斯（Naive Bayes）
	支持向量机（SVM）
	感知器（Perceptron）
	深度神经网络（DNN）

__线性回归：__
 
在一些数据集不大、不复杂的问题和一些经典问题上面有一个很好的效果，训练的程度也不像神经网络那样需要大量的GPU并且分布式的进行训练，可能只要在你的笔记本电脑或者几台服务器上面就能达到效果，当然如果像taobao这样大的推荐系统那肯定是要做分布式了。

__逻辑回归：__
    
一种典型的回归算法(分类)

__决策树：__
    
是一种分类算法，举个例子我们判断一个人玩不玩游戏，我们可以通过他输入的信息，根据特定的条件进行判断，决策树就像是大量if else 语句嵌套的树。叶子节点的结果就是判断的结果。也就是归到哪一个类别下。

__随机森林：__
    ![Image_text](https://raw.githubusercontent.com/OneStepAndTwoSteps/TensorFlow_notes/master/static/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%9B%BE%E4%BE%8B.png)
    
    
决策树的规则设计可能很复杂，有时一个庞大的系统可能不是同一套规则可以去决定的，可能不同的条件适用于不同的规则，这时候我们可以使用随机森林算法，随机森林下有很多决策树，每一个决策树通过你的输入数据都会得到一个类别标签，最简单的判断分类标签的方法，我们可以通过随机森林下决策树输出的哪种标签最多，我们就判断他是哪一种标签。我们有时候也会为决策树增加权重，权重越高，代表的票数越多，然后再判断标签。

__支持向量机：__
    
在一个很高维的场景中，我们很难将其可视化，在一个二维的图像上我们可以通过两个直角坐标系就可以分割出不同类别，在三维上我们可以通过平面切分不同的类别，在更高维的情况下我们很难再去切分，尤其是当这个特征本身(线性代数中的机)，如果找不到机是很难去切分这个特征的，SVM可以帮助我们去做一些机的变换，让你很好的找到一个特征空间，特征空间中的值就比较好去做切分

![Image_text](https://raw.githubusercontent.com/OneStepAndTwoSteps/TensorFlow_notes/master/static/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/%E5%90%91%E9%87%8F%E6%9C%BA%E5%9B%BE%E4%BE%8B.png)

在一个input space(如一个平面图中)中我们很难去发现数据的规律，他可能是一个很复杂的函数，还可能存在过拟合的风险才能将两类数据分隔开，这个时候我们做一个特征变换，将其放在某一个特征空间Feature space之后，我们可以发现两个数据分割很开(我们可以通过一个很简单的平面将两类数据分割)，这样函数的复杂度也大大下降，这只是一个二分类的问题，当我们数据类型很多时SVM的效果也会更加大。


__深度神经网络：__
      
好处在于大量的参数不需要认为去设计，而是通过大量的数据训练，直接拟合出你想要的模型，这依赖于大量的数据，所以深度神经网络成功的前提是你的数据量足够多，可以喂饱你的模型，否则可能就会出现你的模型过于复杂，而你的数据量不够多，这就会出现欠拟合的情况。这样模型就会不够好。


__线性回归：__

在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或者多个自变量和因变量之间的关系进行建模的一种回归分析，这种函数是一个或多个称为回归系数的模型参数的线性组合。

	当我们对一个自变量或者因变量进行建模的时候。我们通常称为单变量的线性回归，多变量建模时就称为多变量线性回归。

最小二乘函数就是我们线性回归中的损失函数 这样的函数通常是一个或多个称为回归系数模型参数的一个线性组合，线性回归就是线性函数的组合，不存在一个线性函数和一个非线性函数的组合。

	当我们的函数是 y=wx+b 我们称为这样的函数为线性函数，如果一个函数为 y=x^2 +b 那么我们称为这样的函数为非线性的函数，因为他不是线性组合了。


	图中的点就是我们的输入数据，我们希望通过线性回归的方法求出函数的表达式(模型)，这样当我们输入未来数据的时候，我们通过x(输入数据)得到y(输出数据) 这就是线性回归的作用


__单变量线性回归：__

训练数据和训练数据其实都是抽样的样本，他并不是我们实际情况或者说是理想情况的数据分布，当我们使用深度学习的时候采用了大量的数据，这些大数据可以使我们尽量的靠近我们的数据分布，在一些传统的机器学习方法中尤其在基于统计学的机器学习方法中很多时候抽样的成本是很高的，所以数据的分布有时候可能完全等于真实的分布，可能是有一定测差距的，我们通过这样的数据拟合出来的函数，我们想尽量的靠近我们的理想函数，它的输出值尽可能的等于我们理想函数的输出值，这时，我们就需要去关注模型的参数。

	比如函数 y = wx + b  w和b就是我们关注的模型参数


	对于我们来说，单变量的线性回归的形式是固定的 他就是等于 y = wx + b  这样一个形式，那b和w到底取决于多少呢？如何求出更好的w和b呢？

	这时候我们需要假设一个函数，这个函数和我们理想的函数的形式是一致的比如 

	hθ(x)=θ0 +θ1x1 = θ^Tx

这个函数的θ0和θ1就对应我们模型中的 b和w ，但是并不完全等同，第一因为数据的本身并不代表真实的分布，第二就是我们设计出来的函数不能过拟合，最终我们还是保证我们假设出的函数hθ(x)和真实值y的差距足够小。

	为了更好的进行矩阵预算，我们通常将 hθ(x)=θ0 +θ1x1 = θ^Tx 写成 hθ(x)=θ0x0 +θ1x1 = θ^Tx   (x0=1) 这样我们就可以通过矩阵运算计算出hθ(x)

	损失值就是 loss=y-hθ(x)  当损失值越来越小的时候，我们的假设函数就越来越靠近我们的理想函数，这个时候我们的假设函数就越来越靠近我们的真实分布。

	为了从一组样本(x(i),y(i))(其中i=1,2....,n)之中估计最合适(误差最小)的θ0和θ1，通常采用最小二乘法，其优化目标为最小化参差平方和：



__梯度下降：__

![Image_text](https://raw.githubusercontent.com/OneStepAndTwoSteps/TensorFlow_notes/master/static/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%9B%BE%E4%BE%8B3.png)
![Image_text](https://raw.githubusercontent.com/OneStepAndTwoSteps/TensorFlow_notes/master/static/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%9B%BE%E4%BE%8B2.png)
![Image_text](https://raw.githubusercontent.com/OneStepAndTwoSteps/TensorFlow_notes/master/static/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%9B%BE%E4%BE%8B.png)

__这里对梯度下降做一个简单的介绍，与公式相结合：__
     从上图看，高度表示j(θ)就是误差，底下的两个坐标系分别是θ0和θ1，刚开始我们的模型参数可能在一个比较高的值，这一个图其实就是表示我们的损失函数想要找到一个全局最小值，但是在一个高维的情况下，我们很难找到一个全局最小值，我们可能只能找到一个局部最优值，在这个过程中我们通过不断的修改θ0和θ1使得我们得出的损失函数越来越小，图二可以看出我们选出了一条优化路径，刚开始的θ的值可能是随机的值，也可能是我们赋的值，但是在之后的一次次更新之后，最终找到了一个最优的点。图三是通过某一个学习率下达到的，实际上修改α其实就是修改我们每一次梯度下降的幅度，举了例子，我们把梯度下降的过程当作人从山上走到山谷的过程，我们肯定是向坡度最陡的方向向下走，这个时候我们的损失值是下降的最快的，当学习率为0.01时就比如我们下山一次走的长度为1步，当学习率为0.1时相当于我们下山一次走了10步的距离。在刚开始的时候我们在山峰上，我们似乎比较容易判断出坡度最陡的位置在何处，这个时候我们步子迈大一点是没问题的，但是如果我们处在一个比较平坦的位置，那我们步子该迈多大呢，这个时候我们需要经常去调整我们的超参数，调整我们的步幅(学习率)，让我们往最陡的地方走。同时步幅如果太大，我们可能会直接越过最优值。这就需要我们基类经验然后进行调参。


我们在损失函数中增加了一个数据，在梯度下降中也是一样 我们只是多了一个输入数据，一开始我们是x跟y的这样的训练数据，单变量中输入只有一个输出只有一个，多变量中我们输入的数据就变多了，可能有房屋的大小，卧室的数量，最后得出价格，这样就是两个变量，现在我们要估计θ0 θ1 θ2这三个参数，使得我们拟合出更适合的模型。
