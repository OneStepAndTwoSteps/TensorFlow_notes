# 多变量房价预测模型 
     
     
## 数据的准备工作
  import pandas as pd
  import numpy as np

  def normalize_feature(df):
      return df.apply(lambda column: (column - column.mean()) / column.std())


  df = normalize_feature(pd.read_csv('data1.csv',
                                     names=['square', 'bedrooms', 'price']))

  ones = pd.DataFrame({'ones': np.ones(len(df))})# ones是n行1列的数据框，表示x0恒为1
  df = pd.concat([ones, df], axis=1)  # 根据列合并数据

  X_data = np.array(df[df.columns[0:3]])
  y_data = np.array(df[df.columns[-1]]).reshape(len(df), 1)

  print(X_data.shape, type(X_data))
  print(y_data.shape, type(y_data))


## 创建线性回归模型（数据流图）

  import tensorflow as tf

  alpha = 0.01 # 学习率 alpha
  epoch = 500 # 训练全量数据集的轮数

  with tf.name_scope('input'):
      # 输入 X，形状[47, 3]
      X = tf.placeholder(tf.float32, X_data.shape, name='X')
      # 输出 y，形状[47, 1]
      y = tf.placeholder(tf.float32, y_data.shape, name='y')

  with tf.name_scope('hypothesis'):
      # 权重变量 W，形状[3,1]
      W = tf.get_variable("weights",
              (X_data.shape[1], 1),initializer=tf.constant_initializer())
      # 假设函数 h(x) = w0*x0+w1*x1+w2*x2, 其中x0恒为1
      # 推理值 y_pred  形状[47,1]
      print(W)

      y_pred = tf.matmul(X, W, name='y_pred')

  with tf.name_scope('loss'):
      # 损失函数采用最小二乘法，y_pred - y 是形如[47, 1]的向量。
      # tf.matmul(a,b,transpose_a=True) 表示：矩阵a的转置乘矩阵b，即 [1,47] X [47,1]
      # 损失函数操作 loss
      loss_op = 1 / (2 * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=True)
  with tf.name_scope('train'):
      # 随机梯度下降优化器 opt
      train_op = tf.train.GradientDescentOptimizer(learning_rate=alpha).minimize(loss_op)

## 创建会话（运行环境）

  with tf.Session() as sess:
      # 初始化全局变量
      sess.run(tf.global_variables_initializer())
      # 开始训练模型
      # 因为训练集较小，所以每轮都使用全量数据训练
      for e in range(1, epoch + 1):
          sess.run(train_op, feed_dict={X: X_data, y: y_data})
          if e % 10 == 0:
              loss, w = sess.run([loss_op, W], feed_dict={X: X_data, y: y_data})
              log_str = "Epoch %d \t Loss=%.4g \t Model: y = %.4gx1 + %.4gx2 + %.4g"
              print(log_str % (e, loss, w[1], w[2], w[0]))

## 分为三个部分进行说明：

__一：数据的处理__

我们假设的函数为hθ(x)=θ0 +θ1x1 = θ^Tx    但是之后我们想要通过矩阵相乘的方式得到 hθ(x)=θ0x0 +θ1x1 = θ^Tx   (x0=1) 这样的话，我们就需要在外面的数据中在新增一列数据，就是x0，如何新增这一列呢，这里我们为大家介绍一个数据处理库numpy

NumPy 是一个 BSD 开源协议许可的，面向 Python 用户的基础科学计算库，在多 维数组上实现了线性代数、傅立叶变换和其他丰富的函数运算。

Numpy和TensorFlow直接的关系也很紧密，我们可以将numpy和Tensor进行数据的互换，这样熟悉numpy，我们也可以通过使用numpy，来使用tensor(张量)

前面的几行代码和之前讲的含义是一样的，我们读取csv文件中的数据，然后传入到normalize_feature 进行一个数据归一化操作，然后将归一化后的结果传给df变量。

ones = pd.DataFrame({‘ones’: np.ones(len(df))})# ones是n行1列的数据框，表示x0恒为1 

上面代码通过pd.DataFrame创建了一个dataframe结构，dataframe支持通过很多种方法构造，第一种方法是通过字典的方式进行构造，就是我们代码中的构造方式 ({‘ones’: np.ones(len(df))｝  ones是我们的key，也就是列名，列中的数据通过np.ones来填充 表示全部以1来填充，一共填充多少行呢？ 行数就是len(df)的长度，这样我们就构造了
n行1列的数据框。

现在这个ones数据框还是独立在外的，我们还没有将ones这个数据框和我们的df数据框进行合并。

df = pd.concat([ones, df], axis=1)  # 表示根据列合并数据


合并之后，我们的前面三列数据就是我们的x，即我们的输入数据，后面的y就是我们的输出数据，这个时候我们的准备工作已经准备好了。

__二：数据流图的创建__
  
  1.首先我们想要定义一个 h(x) = w0*x0+w1*x1+w2*x2, 其中x0恒为1 的假设函数。

如何定义呢？

2. 首先我们定义我们的输入数据和输出数据的模型(数据流图)，因为我们是在会话中训练数据的时候才把我们的输入数据和输出数据填充进数据流图，所以我们先用占位符创建一个数据类型和数据形状即可，在经过我们的归一化操作之后他是一个浮点数，所以我们使用浮点数定义，同时定义我们的X(输入数据的形状为[47,3]，根据我们之前的数据形状定义) y也同理。

3. W = tf.get_variable("weights", (X_data.shape[1], 1),initializer=tf.constant_initializer())
定义我们的权重变量，因为我们的假设函数为个 h(x) = w0*x0+w1*x1+w2*x2，而且从我们的输入数据X中可以看到变量数量是3个，所以我们W的形状应该是[3,1] ，所以我们代码中(X_data.shape[1], 1)表示的就是我们的行数和X中的列数保持一致也就是3，同时将列数设置为1 ,W就是我们常用公式hθ(x)=θ^Tx中θ的转置。此时我们在计算我们的假设函数hθ(x)时我们就可以直接进行我们的矩阵相乘 hθ(x)=tf.matmul(X, W)

然后我们给我们的权重变量附一个值，其中的weights就是我们的权重，同时给他设置了初始化变量的值initializer=tf.constant_initializer() 默认为1，就是我们的权重的值。

get_variable方法和variable方法相比有什么好处呢？

在训练的时候我们使用get_variable方法可以直接获取到我们当前数据流图中名为你设置的名称这个变量的值，以上图为例，就是我们获取名为weight的变量的值。
也就是说在我们进行反复训练的时候，我们可能会从我们的checkpoint中获取我们的之前的模型参数，他可以快速的帮我们找到我们模型参数的值，当我们要加载我们的模型参数到数据流图中时，我们就可以通过我们的key:value的格式找到我们对应参数的值了。对我们进行参数的赋值加载有一个很好的作用。 同时也支持我们initializer初始化。



4.当我们定义好权重变量之后，我们该定义我们的假设模型了。
  
之前我们有说个hθ(x)=θ^Tx，这里的W等于θ^Tx，所以求假设函数hθ(x)时我们就可以直接进行我们的矩阵相乘 hθ(x)=tf.matmul(X, W)

就是我们的[47,3]这个形状的矩阵乘以[3,1]这个形状的矩阵。最后我们的到的就是[47,1] 47行1列的预测值。


5.我们预测输出来的y_pred需要和真实的y进行一个比较，也就是算出我们的误差值。这里的损失函数我们使用最小二乘法来计算。
	     	             n
我们之前有说过最小二乘法的公式：J(θ)=1/2m Σ (hθ(x)-y)^2                    现在我们只是将公式稍微做了一些改变其实含义不变 接下来我们看一下我们做了什么操作
		             i=1

loss_op = 1 / (2 * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=True)

我们先做一个hθ(x)-y的平方，因为(y_pred - y) 就是hθ(x)-y，所以我们通过调用tf.matmul 方法使得矩阵(y_pred - y)乘上矩阵 (y_pred - y)就是我们hθ(x)-y的平方，但是这样有一个问题因为(y_pred - y),是一个[47,1]的矩阵，所以两个[47,1]的矩阵是无法相乘的所以我们将第一个hθ(x)-y也就是我们的第一个(y_pred – y)转置，transpose_a=True就是表示转置矩阵a，也就是第一个(y_pred – y)。这里注意，如果我们转置矩阵b我们的出来的结果就是[47,1]形状的矩阵，就不是所有误差值相加后的结果了
	     	          	       n
转置之后相乘结果为[1,1]形状的矩阵也就是我们最小二乘法中的Σ (hθ(x)-y)^2    就是将所有的误差值算出来并且相加，得到我们所有的误差值。
			       i=1

之后就和我们的最小二乘公式一样了1 / (2 * len(X_data)) 就相当于我们的1/2m ，len(X_data)就是要求得我们的数据条数。


6.当我们定义好了损失函数，接下去我们要进行一个优化

opt = tf.train.GradientDescentOptimizer(learning_rate=alpha)
train_op=opt. minimize(loss_op)
这里使用梯度下降的方法进行优化，这条代码定义了一个随机梯度优化器，同时我们给优化器传入一个learning_rate=alpha 也就是我们的学习率，这时候我们就定义好了一个优化器opt。

然后我们通过train_op=opt. minimize(loss_op)，我们通过传入我们的损失函数，通过minimize不断的进行最小化。这个时候我们得到的模型参数就是我们想要的模型参数。

__三：创建会话__

我们已经定义好了一个模型参数，那我们如果要对我们的模型参数进行训练我们需要创建一个会话。

创建会话的时候可以通过python的with语句来创建 就是代码     with tf.Session() as sess:

之后我们初始化我们的变量sess.run(tf.global_variables_initializer()) 这是我们在执行训练之前的必须操作，这里就不再赘述。

接下来我们就可以训练我们的模型，for e in range(1, epoch + 1):表示我们训练epoch轮我们的数据，一轮代表一次数据流图的训练，也就是我们一次epoch就是训练我们的47组数据，当我们进行一次全量数据集的训练，我们就可以理解为我们进行了一次epoch。

因为我们现在训练的数据较小，所以我们每一次训练都可以将我们的所有数据遍历一遍，但是如果我们的数据量很大的时候，如果想要遍历全部数据就很难。我们可以采用如 批梯度下降的算法。这里我们采用梯度下降的算法。

 sess.run(train_op, feed_dict={X: X_data, y: y_data})代码的意思是，我们执行我们的目标函数train_op，同时将我们的数据传入到我们的placehodler中，也就是代码中的feed_dict={X: X_data, y: y_data} 操作。

 然后我们设置每10个epoch输出我们的loss模型参数值 if e % 10 == 0: 意为如果e除以10所得余数为0，即进行下面操作。

loss, w = sess.run([loss_op, W], feed_dict={X: X_data, y: y_data}) 我们通过执行此代码，将会话中的 loss和w的值赋值给我们的loss和w变量 。

最后通过下面这两行代码打印出我们的参数。
            log_str = "Epoch %d \t Loss=%.4g \t Model: y = %.4gx1 + %.4gx2 + %.4g"
            print(log_str % (e, loss, w[1], w[2], w[0]))

我们可以看到我们的输出结果。


