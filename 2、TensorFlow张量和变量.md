# TensorFlow张量和变量：


## TensorFlow张量：
	张量：
		在数学里张量是一种几何实体，广义上表示任何形式的“数据”，张量可以理解为0阶(rank),标量、一阶向量和2阶矩阵在高维空间上的推广，张量的阶描述它表示数据的最大维度。

	举个例子：
		张量可以理解为在我们0阶的时候我们称它为标量比如说1，2，3，4，5，6，7，8，在一阶的时候我们可以称他为向量，比如中学的平行四边形原理，其实就是向量相加。矩阵就是我们二阶的张量，就像下面我们举得例子这样的两个维度的数据了。除此以外我们还可以往高维空间上做推广，比如说三阶的张量，其实就像数据立方一样，三阶以上我们就很难在平面图中展现出来了，大家可以在脑海中想象，或者说能抽象的去定义他，然后在之后直接去使用这个数据就好了，而不需要想象出他是一个什么样的形状。
			0阶				一阶							二阶		           三阶         10  11   12
				1				1 2 3							1 2 3             		立体图 1  2  3  15
																4 5 6                          4  5  6 18
																7 8 9                          7  8  9

		三阶的图形做了一个图例：
			他不仅在平面这一层是有数据的，其实张量就是这样一种东西，在数学中表示任意的一种数据，在我们的模型训练中当然可能会遇到各种各样的数据，所以我们在TensorFlow中里面引入了张量的定义，------维基百科



	在TensorFlow中张量的实现方式：
		在TensorFlow中张量表示某种相同"数据类型"的"多维数组"
			张量的两个重要属性：
				1.数据类型(如：浮点型，整型，字符串)
				2.数组形状(各个维度的大小)

			其实这里说的数组就是张量的形状的一个定义：
				比如刚开始的时候我们有提到一个一阶，二阶，三阶的数组，但是比如说我们现在定义一个三阶的数组，但是这个三阶数组的个个维度是长什么样的呢？就比如说一个数组是三阶，那第一阶的维度是多少呢？ 假设我们将平面这一层定义为第一阶第二阶，我们可以看出他第一阶和第二阶的维度就是3。
				深度这一阶我们根据图可以看出是2，这个其实是一个很重要的概念，大家可以将张量的阶理解成这个张量有多少个维度。

				比如说他说一个三阶的张量，那么他就有三个方向可以去延展，但是每一个维度里面，或者说每一阶里面，他的维度值有多大，他有多长，他的尺寸是多少，这些都是需要明确定义的，比如说你现在只告诉我你想要做一个数据立方，如果没有告诉我维度，那这个数据立方可以是各种各样的比如说一个3*3*2这样一个形状的数据立方，也有可能是一个3*3*4的数据立方，所以这里需要一个形状这样的一个属性来描述我们的张量。

			但是这里要注意的是必须是某种相同类型的多维数组，因为当你一个张量中描述的数据类型不一样的时候其实是很难去进行计算的，大家可以去想象一下一个二阶的张量，当我们这个二阶数组的第一个元素是整型，第二个元素是浮点型，第三元素是字符串的时候，如果想要取和其他的数组去做计算的时候其实是很难进行计算的。所以在模型训练中也不太会有这样的场景出现。所以说TensorFlow也没有基于这样的实现。



			所以我们在定义张量的时候我们要注意，要保证张量中的元素数据类型是一致的，并且明确的描述出这个数组的形状。


		在TensorFlow中张量是什么？

			1.张量是用来表示多维数据的。 
				 我们可以用它来表示一维二维三维n维的数据，其实n阶的一个数组是可以被一个多维的数组表示出来。

			2.张量是执行操作时的输入或输出数据。
				在之前我们讲过的数据流图中，边里面其实流动的就是数据，那这个边就是我们的张量，每一个节点就是我们的操作，在我们执行操作的时候是需要输入数据的，之前我们就有举过一个y=a+b的一个例子，a和b其实就是我们的输入数据，这个是要通过张量将我们的数据流到操作节点上进行运算，当我们算完a+b的结果等于y，那么这个y就会作为下一个操作的输入数据。所以说a+b这个操作输出的数据也是用张量来表示的，当我们去执行操作的时候就需要张量这么一个抽象来表示数据，并且输入到我们的操作节点当中。

			3.用户通过执行操作来创建或计算张量
				那我们如何创建一个张量呢张量的创建其实不需要通过类的构造方法去创建的，而是可以通过执行一个操作来创建的

			4.张量的形状不一定在编译时确定，可以在运行时通过形状推断计算得出。
				开头的时候我们说过形状的定义很重要，我们这里说的形状定义是指在实际的运行时，必须要把形状定义下来，比如说我们现在做一个两个矩阵的相乘，但是你现在不清楚矩阵的形状，你是无法去做相乘的。但是我们在写代码的时候是不一定知道形状的，因为这是和你的输入数据相关的，我们刚开始的时候有看到在我们的数据流图里面，input这个数据节点是我们的输入数据，输入数据如果大家有训练模型的基础的话，可能会知道一些超参数，比如我们每一个批数据(batch_size)到底是多少，这个就决定了当我们进行大量的矩阵运算的时候，初始的形状到底是什么，所以说通俗的做法是，我们在定义一个模型参数的时候，我们可能会把我们的形状某一个部分是预留的，也就是说某一个部分不是马上确定的，我们可以通过一个缺省的方式先留在那，然后在实际运行的时候通过形状推断，比如说我们的batch_size设置为32，最后能推断出运行到这一步的时候，运算到这一层的时候，当前的这个张量，当前的这个数组到底是什么形状。所以说这个也是TensorFlow在实现计算的时候为大家预留的一个很好的特性使得我们的计算可以更加的灵活，如果没有这样的一个特性，可能 每当我们去画一个batch_size的时候都要去改一遍代码，这个是非常的不灵活的。


		TensorFlow中几类特殊的张量，由一下操作产生：


			tf.constant //常量

			tf.placehodler //占位符

			tf.Variable //变量


			刚刚有提到张量是由操作产生的，通过执行一些操作我们可以去操作和计算一些张量，操作其实有很多种，这里我们举了几类特别的张量
			常量：
			比如说常量的操作，常量是很多语言中都有的一个概念，常量操作其实就是一种最普通的张量当使用常量操作创造出张量这个张量的值是不可改变的，这个不可改变其实是张量中一个很重要的概念，也很容易和传统的编程语言搞混，就因为在一个特定的操作执行过程当中，张量一定是不可改变的，大家可以想象在我们的数据流图中流动的时候，从一个节点流动到另一个节点，这条边中的数据这个值是不可改变的，也就是说当我们执行一个y=a+b的时候这个a和b的值是无法改变的，当你执行完一个a+b的时候，你可能会有新的输入数据，会再次执行a+b这个时候可能因为你的输入数据变了a和b就已经变化了，但是这个时候你的值就无法用常量的操作去创建，因为常量操作创建出来的值，是不论你怎么改变输入数据他都是不能改变的一个量，大家可以理解为这是一个TensorFlow编程中的一个常		

			placehodler：
			可以简单的理解为他说描述数据的一个壳，本身是需要通过数据流图外面的数据填充进来，才可以得到数据的一种操作，如何填充这样的数据我们之后会做介绍
				例子：比如我们定义一个三阶的张量，我们可以想象我们的形状是 3* 3 *2 ，如果我们使用常量来定义的话，这个数据形状以后就无法改变除非你去定义一个新的操作，重新得到一个新的值，但是如果你是使用占位符的话，其实你是得到一个3*3*2这个数据立方的壳，里面是没有任何的值的，当你每次从数据流图外向里面填充数据的时候，在那个时刻，才能得到数据，比如说我们现在的模型里面的值是123456789，之后如果想要把他覆盖再填充也是没有问题的，而且你可以不用一次性的完整定义形状 而只是先定义一个3*3然后空下来一个维度，然后这个立方就变成了一个平面确定，深度不确定的一个立方，然后在外面填充数据的时候再去定义这个深度有深。这个就给模型的训练和数据的填充留下了一个灵活的接口。

			变量：
				维护特殊张量的状态。使得这个值在数据流图运行结束后也不会被释放，会一直常驻内存使得我们的值可以保存下来。
				在下一个小结中介绍

  总结：
  
    TensorFlow的张量其实是表示数据的，可以表示任意维度的数据，在张量中有一个特殊的张量也就是常量，用常量创建出的张量是不可以改变的，占位符产生的其实就是一个高维数据的壳，他需要在图外填充数据，在运行时的时候才可以得到一个确定的张量，还有一个变量他可以用来维护特殊张量的状态。使得这个值在数据流图运行结束后也不会被释放，会一直常驻内存使得我们的值可以保存下来。





TensorFlow张量(下)：

	之前的课程中我们已经讲过了如何安装一个jupyter notebook，现在我们启动他 然后打开


	tf.Variable(参数，数据类型(可以不写，不写的时候由TensorFlow自己推断)，变量名(可以默认不写))

	分别是在内存中的名字     他们的形状      数据类型
	variable：0                shape          dtype=int..
	variable_1：0              shape          dtype=..
	variable_2：0              shape          dtype=..
	variable_3：0              shape          dtype=..



	阶和维度：
		其实阶就是定义了我们一个张量描述的最大维度有多少个，比如说我们是一个三阶的张量我们可以在x,y,z直角坐标系图中任意的去表示，如果我们是一个二阶的张量，我们是无法突破第三个维度的




## TensorFlow变量：


